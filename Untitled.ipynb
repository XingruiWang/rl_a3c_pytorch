{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML,Image\n",
    "\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    #plt.title(\"%s | Step: %d %s\" % (env._spec.id,step, info))\n",
    "    plt.axis('off')\n",
    "    plt.savefig('video/{}.png'.format(step))\n",
    "\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video():\n",
    "  mp4list = glob.glob('video/*.mp4')\n",
    "  if len(mp4list) > 0:\n",
    "    mp4 = mp4list[0]\n",
    "    video = io.open(mp4, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "  else: \n",
    "    print(\"Could not find video\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import argparse\n",
    "import torch\n",
    "from environment import atari_env\n",
    "from utils import read_config, setup_logger\n",
    "from model import A3Clstm\n",
    "from player_util import Agent\n",
    "import gym\n",
    "from gym import wrappers\n",
    "from gym.wrappers import Monitor\n",
    "import logging\n",
    "import time\n",
    "#from gym.configuration import undo_logger_setup\n",
    "\n",
    "#undo_logger_setup()\n",
    "parser = argparse.ArgumentParser(description='A3C_EVAL')\n",
    "parser.add_argument(\n",
    "    '--env',\n",
    "    default='MsPacman-v0',\n",
    "    metavar='ENV',\n",
    "    help='environment to train on (default: Pong-v0)')\n",
    "parser.add_argument(\n",
    "    '--env-config',\n",
    "    default='config.json',\n",
    "    metavar='EC',\n",
    "    help='environment to crop and resize info (default: config.json)')\n",
    "parser.add_argument(\n",
    "    '--num-episodes',\n",
    "    type=int,\n",
    "    default=5,\n",
    "    metavar='NE',\n",
    "    help='how many episodes in evaluation (default: 100)')\n",
    "parser.add_argument(\n",
    "    '--load-model-dir',\n",
    "    default='trained_models/',\n",
    "    metavar='LMD',\n",
    "    help='folder to load trained models from')\n",
    "parser.add_argument(\n",
    "    '--log-dir', default='logs/', metavar='LG', help='folder to save logs')\n",
    "parser.add_argument(\n",
    "    '--render',\n",
    "    default=False,\n",
    "    metavar='R',\n",
    "    help='Watch game as it being played')\n",
    "parser.add_argument(\n",
    "    '--render-freq',\n",
    "    type=int,\n",
    "    default=1,\n",
    "    metavar='RF',\n",
    "    help='Frequency to watch rendered game play')\n",
    "parser.add_argument(\n",
    "    '--max-episode-length',\n",
    "    type=int,\n",
    "    default=10000,\n",
    "    metavar='M',\n",
    "    help='maximum length of an episode (default: 100000)')\n",
    "parser.add_argument(\n",
    "    '--gpu-id',\n",
    "    type=int,\n",
    "    default=-1,\n",
    "    help='GPU to use [-1 CPU only] (default: -1)')\n",
    "parser.add_argument(\n",
    "    '--skip-rate',\n",
    "    type=int,\n",
    "    default=4,\n",
    "    metavar='SR',\n",
    "    help='frame skip rate (default: 4)')\n",
    "parser.add_argument(\n",
    "    '--seed',\n",
    "    type=int,\n",
    "    default=1,\n",
    "    metavar='S',\n",
    "    help='random seed (default: 1)')\n",
    "parser.add_argument(\n",
    "    '--new-gym-eval',\n",
    "    default=False,\n",
    "    metavar='NGE',\n",
    "    help='Create a gym evaluation for upload')\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "setup_json = read_config(args.env_config)\n",
    "env_conf = setup_json[\"Default\"]\n",
    "for i in setup_json.keys():\n",
    "    if i in args.env:\n",
    "        env_conf = setup_json[i]\n",
    "\n",
    "gpu_id = args.gpu_id\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if gpu_id >= 0:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "saved_state = torch.load(\n",
    "    '{0}{1}.dat'.format(args.load_model_dir, args.env),\n",
    "    map_location=lambda storage, loc: storage)\n",
    "\n",
    "log = {}\n",
    "setup_logger('{}_mon_log'.format(args.env), r'{0}{1}_mon_log'.format(\n",
    "    args.log_dir, args.env))\n",
    "log['{}_mon_log'.format(args.env)] = logging.getLogger('{}_mon_log'.format(\n",
    "    args.env))\n",
    "\n",
    "d_args = vars(args)\n",
    "for k in d_args.keys():\n",
    "    log['{}_mon_log'.format(args.env)].info('{0}: {1}'.format(k, d_args[k]))\n",
    "\n",
    "env = atari_env(\"{}\".format(args.env), env_conf, args)\n",
    "num_tests = 0\n",
    "start_time = time.time()\n",
    "reward_total_sum = 0\n",
    "player = Agent(None, env, args, None)\n",
    "player.model = A3Clstm(player.env.observation_space.shape[0],\n",
    "                       player.env.action_space)\n",
    "player.gpu_id = gpu_id\n",
    "if gpu_id >= 0:\n",
    "    with torch.cuda.device(gpu_id):\n",
    "        player.model = player.model.cuda()\n",
    "if args.new_gym_eval:\n",
    "    player.env = gym.wrappers.Monitor(\n",
    "        player.env, \"{}_monitor\".format(args.env), force=True)\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    with torch.cuda.device(gpu_id):\n",
    "        player.model.load_state_dict(saved_state)\n",
    "else:\n",
    "    player.model.load_state_dict(saved_state)\n",
    "\n",
    "player.model.eval()\n",
    "for i_episode in range(args.num_episodes):\n",
    "    player.state = player.env.reset()\n",
    "    player.state = torch.from_numpy(player.state).float()\n",
    "    if gpu_id >= 0:\n",
    "        with torch.cuda.device(gpu_id):\n",
    "            player.state = player.state.cuda()\n",
    "    player.eps_len += 2\n",
    "    reward_sum = 0\n",
    "    while True:\n",
    "        if args.render:\n",
    "            if i_episode % args.render_freq == 0:\n",
    "                player.env.render()\n",
    "\n",
    "        player.action_test()\n",
    "        reward_sum += player.reward\n",
    "\n",
    "        if player.done and not player.info:\n",
    "            state = player.env.reset()\n",
    "            player.eps_len += 2\n",
    "            player.state = torch.from_numpy(state).float()\n",
    "            if gpu_id >= 0:\n",
    "                with torch.cuda.device(gpu_id):\n",
    "                    player.state = player.state.cuda()\n",
    "        elif player.info:\n",
    "            num_tests += 1\n",
    "            reward_total_sum += reward_sum\n",
    "            reward_mean = reward_total_sum / num_tests\n",
    "            log['{}_mon_log'.format(args.env)].info(\n",
    "                \"Time {0}, episode reward {1}, episode length {2}, reward mean {3:.4f}\".\n",
    "                format(\n",
    "                    time.strftime(\"%Hh %Mm %Ss\",\n",
    "                                  time.gmtime(time.time() - start_time)),\n",
    "                    reward_sum, player.eps_len, reward_mean))\n",
    "            player.eps_len = 0\n",
    "            break\n",
    "        show_state(env.env, i_episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
